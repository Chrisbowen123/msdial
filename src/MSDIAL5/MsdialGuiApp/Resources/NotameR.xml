<?xml version="1.0" encoding="utf-8"?>
<Rscript xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
	<Script>
		<![CDATA[
# RHaikonen
# 20231110
# Overall view of notame preprocessing and quality metrics

# Load libraries
# library(notame)
# library(doParallel)
# library(dplyr)
# library(openxlsx)
library(RODBC)
# Functions to import Ms-dial export
name_features <- function (feature_data, ion_mod) 
{
cols <- find_mz_rt_cols(feature_data)
mz_col <- cols$mz_col
rt_col <- cols$rt_col
round_mz <- as.numeric(feature_data[, mz_col]) %>% as.character() %>% 
gsub("[.]", "_", .)
round_rt <- as.numeric(feature_data[, rt_col]) %>% as.character() %>% 
gsub("[.]", "_", .)
feature_data$Feature_ID <- paste0(ion_mod, "_", 
                                round_mz, "a", round_rt)
if (anyDuplicated(feature_data$Feature_ID)) {
duplicates <- paste0(feature_data$Feature_ID[duplicated(feature_data$Feature_ID)], 
                        collapse = ", ")
stop(paste0("Could not create unique feature names from m/z and retention time columns. Duplicated values: ", 
            duplicates))
}
feature_data
}
find_mz_rt_cols <- function (feature_data) 
{
mz_tags <- c("mass", "average mz", "average.mz", "molecularweight", 
            "molecular weight", "average_mz")
rt_tags <- c("retention time", "retentiontime", "average rt[(]min[)]", 
            "average[_]rt[_]min[_]", "average[.]rt[.]min[.]", "^rt$")
mz_col <- NULL
for (tag in mz_tags) {
hits <- grepl(tag, tolower(colnames(feature_data)))
if (any(hits)) {
    mz_col <- colnames(feature_data)[which(hits)[1]]
    break
}
}
rt_col <- NULL
for (tag in rt_tags) {
hits <- grepl(tag, tolower(colnames(feature_data)))
if (any(hits)) {
    rt_col <- colnames(feature_data)[which(hits)[1]]
    break
}
}
if (is.null(mz_col)) {
stop(paste0("No mass to charge ratio column found - should match one of:\n", 
            paste(mz_tags, collapse = ", "), " (not case-sensitive)"))
}
if (is.null(rt_col)) {
stop(paste0("No retention time column found - should match one of:\n", 
            paste(rt_tags, collapse = ", "), " (not case-sensitive)"))
}
return(list(mz_col = mz_col, rt_col = rt_col))
}


##############################################################
read_MSDIAL <- function(tablefile, ion_mod){
tbl <- read.delim(tablefile, header = F, quote = "")
  
corner_row <- which(tbl[, 1] != "")[1]
corner_column <- which(tbl[1, ] != "")[1]
  
# Featuredata
peakmetadata_cols <- tbl %>%
dplyr::select(1:(corner_column)) %>%
dplyr::slice(corner_row:dplyr::n())
  
colnames(peakmetadata_cols) <- as.character(unlist(peakmetadata_cols[1,]))
row_tbl <- peakmetadata_cols[-1,]
  
row_tbl <- name_features(as.data.frame(row_tbl), ion_mod = ion_mod)
  
rownames(row_tbl) <- row_tbl$Feature_ID
row_tbl$Split <- ion_mod
fData <- as.data.frame(row_tbl)
  
# extract the sample information (pData) and expression table
quantval_cols <- tbl %>% dplyr::select((corner_column+1):ncol(tbl))
  
numof_sample_class <- length(na.omit(unique(unlist(quantval_cols[1,]))))
numof_avgstdev_cols <- numof_sample_class * 2
quantval_cols <- quantval_cols %>%
dplyr::select(1:(ncol(quantval_cols)-numof_avgstdev_cols))
  
# pData
pData <- as.data.frame(t(quantval_cols[c(1:corner_row),]))
  
# colnames for pData
temp <- t(tbl[1:corner_row,corner_column])
temp <- ifelse(temp == "File type", "QC", temp)
colnames(pData) <- temp # c("Class", "FileType","InjectionOrder", "BatchId", "SampleId")
  
pData$Sample_ID <- paste0("Sample_", make.unique(pData$Class, sep = "_"))
  
# final pData
pData <- as.data.frame(pData)
colnames(pData) <- gsub(" ", "_", colnames(pData))
  
rownames(pData) <- pData$Sample_ID
  
# Expression part
quantval_tbl <- as.matrix(quantval_cols[-c(1:corner_row),] %>%
                            dplyr::mutate(across(where(is.character), as.numeric)))
  
rownames(quantval_tbl) <- rownames(fData)
colnames(quantval_tbl) <- rownames(pData)
  
return(list(exprs = quantval_tbl, pheno_data = pData, feature_data = fData))
}


# set up path
# args <- commandArgs(trailingOnly = TRUE)
# path <- args[1]
# file_name <- args[2]
# ion_mod <- args[3]
# path <- "D:\\Notame\\Notame_demo\\result"
# path <- gsub("\\\\", "/", file.path(path, ""))
# path <- file.path(path, "/")
# 
# # either ion_mod or split_col should exist
# # They are needed in metaboset construction
# ion_mod <- "neg" # name the mode
# 
# file_name <- "Height_0_2024_01_31_15_48_27.txt" # name of possible excel file
grouping_name <- "Class" # set the name of group that exist MS-dial

# # Optional logging
# 
# notame::init_log(log_file = paste0(path, "log.txt"))
# #> Logging started: ~/test_project/log.txt.
# # Check logging state
# log_state()
# #> Current log file: ~/test_project/log.txt


# this can be omitted. Depending if the data is read from excel or else where
# Read data from excel file
# (note: as we use split_by here assumption is that the data contains signals from two or more modes)
# One of split_by and name are needed. Depending of the number of modes.
if(ion_mod != ""){
data <- read_MSDIAL(paste0(path, file_name), ion_mod = ion_mod)
# data <- notame::read_from_excel(file = paste0(path, file_name), sheet = 1, name = ion_mod)
}

# # if data have more modes
# if(split_col =! ""){
#   data <- notame::read_from_excel(file = paste0(path, ""), sheet = 1, split_by = split_col)
# }

if (exists("data")) {
# Some adaptations can be done
# Replace spaces with underscores if necessary
rownames(data$exprs) <- gsub(" ", "_", rownames(data$exprs))
rownames(data$feature_data) <- gsub(" ", "_", rownames(data$feature_data))
data$feature_data$Feature_ID <- gsub(" ", "_", data$feature_data$Feature_ID)
  
# Works with one or more modes
# Construct MetaboSet objects
# (note: assumption is that the dataset already contains group information)
metaboset <- notame::construct_metabosets(exprs = data$exprs, pheno_data = data$pheno_data,
                                        feature_data = data$feature_data,
                                        group_col = grouping_name, split_data = F)
  
# # Same can be done without group information
# modes <- notame::construct_metabosets(exprs = data$exprs, pheno_data = data$pheno_data,
#                               feature_data = data$feature_data)
  
  
  
# Preprocessing of ONE mode
# (NB: visualizations disabled here for saving computational time,
# remove the hashtags to enable them.
# Also, create a folder called figures in the working folder if you create visualizations)
  
# First, set all zero abundances to NA and asses the detection rate and flag based on that
metaboset <- notame::mark_nas(metaboset, value = 0)
metaboset <- notame::flag_detection(metaboset)
  
  
# Then check that there is QC samples.
# The whole process is dependent on QC samples
if("QC" %in% metaboset$QC ){
# Take several cores to speed up processing
num_cores <- parallel::detectCores() - 5
cl <- parallel::makeCluster(num_cores)
doParallel::registerDoParallel(cl)
    
# Set the name for visualization and do visualization
# Commented here!
# name <- ""
# visualizations(metaboset, prefix = paste0(path, "figures/", name, "_ORIG"))
    
# Correct the possible drift
corrected <- notame::correct_drift(metaboset, check_quality = T)
# visualizations(corrected, prefix = paste0(path, "figures/", name, "_DRIFT"))
    
# flag based on quality
corrected <- notame::flag_quality(corrected)
# visualizations(corrected, prefix = paste0(path, "figures/", name, "_CLEANED"))
    
# Remove the QCs for imputation
merged_no_qc <- notame::drop_qcs(corrected)
#visualizations(merged_no_qc, prefix = paste0(path, "figures/FULL_NO_QC"))
    
# Imputation
# (note: may not be necessary especially if gap filling by compulsion was used in MS-DIAL)
# Needs missForest package for random forest imputation
    
# Set seed number for reproducibility
set.seed(1234567)
imputed <- notame::impute_rf(merged_no_qc)
imputed <- notame::impute_rf(imputed, all_features = TRUE)
    
    
#Stop using several cores (releases them for other use)
parallel::stopCluster(cl)
    
# Save the merged and processed data
# options to save in rds format or to excel
print("Saving imputed files")
saveRDS(imputed, file = paste0(path, "full_data.RDS"))
write_to_excel(imputed, file = paste0(path, "full_data.xlsx"))
} else{
print("No QC samples so no drift correction nor imputation was done")
    
print("Still saving the RDS and excel for further analysis.")
saveRDS(metaboset, file = paste0(path, "full_data.RDS"))
write_to_excel(metaboset, file = paste0(path, "full_data.xlsx"))
}
} else {
stop("Something went wrong in data reading.")
}
		]]>
	</Script>
</Rscript>
